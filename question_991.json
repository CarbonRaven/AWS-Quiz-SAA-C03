{
  "id": 991,
  "topic": "Topic 1",
  "question": "A company uses GPS trackers to document the migration patterns of thousands of sea turtles. The trackers check every 5 minutes to see if a turtle has moved more than 100 yards (91.4 meters). If a turtle has moved, its tracker sends the new coordinates to a web application running on three Amazon EC2 instances that are in multiple Availability Zones in one AWS Region.\n\nRecently, the web application was overwhelmed while processing an unexpected volume of tracker data. Data was lost with no way to replay the events. A solutions architect must prevent this problem from happening again and needs a solution with the least operational overhead.\n\nWhat should the solutions architect do to meet these requirements?",
  "options": {
    "A": "Create an Amazon S3 bucket to store the data. Configure the application to scan for new data in the bucket for processing.",
    "B": "Create an Amazon API Gateway endpoint to handle transmitted location coordinates. Use an AWS Lambda function to process each item concurrently.",
    "C": "Create an Amazon Simple Queue Service (Amazon SQS) queue to store the incoming data. Configure the application to poll for new messages for processing.",
    "D": "Create an Amazon DynamoDB table to store transmitted location coordinates. Configure the application to query the table for new data for processing. Use TTL to remove data that has been processed."
  },
  "correct_answer": "C",
  "explanation": "SQS provides durable message storage that prevents data loss during traffic spikes. Messages remain in the queue until processed, allowing replay if needed. The application can poll messages at its own pace, preventing overwhelming during high volume periods."
}
