{
  "id": 718,
  "topic": "Topic 1",
  "question": "A company's applications use Apache Hadoop and Apache Spark to process data on premises. The existing infrastructure is not scalable and is complex to manage.\n\nA solutions architect must design a scalable solution that reduces operational complexity. The solution must keep the data processing on premises.\n\nWhich solution will meet these requirements?",
  "options": {
    "A": "Use AWS Site-to-Site VPN to access the on-premises Hadoop Distributed File System (HDFS) data and application. Use an Amazon EMR cluster to process the data.",
    "B": "Use AWS DataSync to connect to the on-premises Hadoop Distributed File System (HDFS) cluster. Create an Amazon EMR cluster to process the data.",
    "C": "Migrate the Apache Hadoop application and the Apache Spark application to Amazon EMR clusters on AWS Outposts. Use the EMR clusters to process the data.",
    "D": "Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Create an Amazon EMR cluster to process the data."
  },
  "correct_answer": "C",
  "explanation": "AWS Outposts brings AWS services, including Amazon EMR, to on-premises environments. This allows scalable Hadoop and Spark processing while keeping data on premises, reducing operational complexity through managed AWS services."
}
