{
  "id": 767,
  "topic": "Topic 1",
  "question": "A pharmaceutical company is developing a new drug. The volume of data that the company generates has grown exponentially over the past few months. The company's researchers regularly require a subset of the entire dataset to be immediately available with minimal lag. However, the entire dataset does not need to be accessed on a daily basis. All the data currently resides in on-premises storage arrays, and the company wants to reduce ongoing capital expenses.\n\nWhich storage solution should a solutions architect recommend to meet these requirements?",
  "options": {
    "A": "Run AWS DataSync as a scheduled cron job to migrate the data to an Amazon S3 bucket on an ongoing basis.",
    "B": "Deploy an AWS Storage Gateway file gateway with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.",
    "C": "Deploy an AWS Storage Gateway volume gateway with cached volumes with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.",
    "D": "Configure an AWS Site-to-Site VPN connection from the on-premises environment to AWS. Migrate data to an Amazon Elastic File System (Amazon EFS) file system."
  },
  "correct_answer": "C",
  "explanation": "Storage Gateway volume gateway with cached volumes keeps frequently accessed data locally while storing the full dataset in S3. This provides low-latency access to active data subsets while reducing capital expenses by using cloud storage for the complete dataset. File gateway would work for file-based access, but cached volumes are better for block storage scenarios."
}
