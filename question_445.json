{
  "id": 445,
  "topic": "Topic 1",
  "question": "A company is storing 700 terabytes of data on a large network-attached storage (NAS) system in its corporate data center. The company has a hybrid environment with a 10 Gbps AWS Direct Connect connection.\n\nAfter an audit from a regulator, the company has 90 days to move the data to the cloud. The company needs to move the data efficiently and without disruption. The company still needs to be able to access and update the data during the transfer window.\n\nWhich solution will meet these requirements?",
  "options": {
    "A": "Create an AWS DataSync agent in the corporate data center. Create a data transfer task. Start the transfer to an Amazon S3 bucket.",
    "B": "Back up the data to AWS Snowball Edge Storage Optimized devices. Ship the devices to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system.",
    "C": "Use rsync to copy the data directly from local storage to a designated Amazon S3 bucket over the Direct Connect connection.",
    "D": "Back up the data on tapes. Ship the tapes to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system."
  },
  "correct_answer": "A",
  "explanation": "DataSync over Direct Connect efficiently transfers large data sets with incremental sync capability, allowing continued access and updates during transfer. With 10 Gbps, 700 TB can transfer in ~7 days (allowing for overhead). Snowball doesn't support continued data updates during transfer. rsync lacks DataSync's optimization and verification. Tape transfer is slow and doesn't allow updates."
}
